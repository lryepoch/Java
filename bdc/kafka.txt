
·kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者在网站中的所有动作流数据。

·kafka通过zookeeper管理集群，在每台服务器上先安装zookeeper；具体管理：
	··探测broker和consumer的添加或移除；
	··负责维护所有partition的领导者/从属者关系（主分区和备份分区），如果主分区挂了，需要选举出备份分区作为主分区；
	··维护topic、partition等元配置信息；
	···。。。
	kafka之间是无法互相发现对方的，每个kafka向zk注册，说我是A节点（broker.id），我是B节点，这样组成了一个kafka集群。每个人通过zk来发现彼此。


·相关概念： 
	broker：一台kafka服务器就是一个broker。一个集群由多个broker组成；
			一个broker可以容纳多个topic，一个topic会分为多个partition，实际上partition会分布在不同的broker中；即同一份topic会分布在多个不同的broker上，由此得知：Kafka是天然分布式的；
			已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器都是一个代理（Broker）；
			消费者可以订阅一个或多个主题（topic），并从Broker拉数据，从而消费这些已发布的消息；

	topic：一个队列，主题；
			为了提高一个队列(topic)的吞吐量，kafka会把topic进行分区(Partition)；
			Topic是Kafka数据写入操作的基本单元，可以指定副本；
			一个Topic包含一个或多个Partition，建议Topic的时候可以手动指定Partition个数，个数与服务器个数相当；
			每条消息属于且仅属于一个Topic；
			Producer发布数据时，必须指定将该消息发布到哪个Topic；
			Consumer订阅消息时，也必须指定订阅哪个Topic的信息；
			往一个topic丢数据，实际上就是往多个broker的partition存储数据；

	partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。
				partition中的每条消息都会被分配一个有序的id（offset）。
				partition中的每条消息都会被分配一个有序的id（offset）。kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体（多个partition间）的顺序。 
				生产者往topic里丢数据是存在partition上的，而partition持久化到磁盘是IO顺序访问的，并且是先写缓存，隔一段时间或者数据量足够大的时候才批量写入磁盘的。 

	offset：kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。
			当然the first offset就是00000000000.kafka。
			
			Kafka就是用offset来表示消费者的消费进度到哪了，每个消费者会都有自己的offset。说白了offset就是表示消费者的消费进度。
			在以前版本的Kafka，这个offset是由Zookeeper来管理的，后来Kafka开发者认为Zookeeper不合适大量的删改操作，于是把offset在broker以内部topic(__consumer_offsets)的方式来保存起来。

			kafka的topic中的每个消费组消费的下标；说白了offset就是表示消费者的消费进度。


	producer：消息生产者，向broker发消息的客户端；

	consumer：消息消费者，向broker取消息的客户端；

	message：消息是kafka处理的对象。在kafka中，消息是被发布到broker的topic中。而consumer也是从相应的topic中拿数据。也就是说，message是按topic存储的；
			 每个消息（也叫记录record，我习惯叫消息）是由一个key，一个value和时间戳构成；

	consumer group：将topic消息的广播发给consumer的手段；一个topic可以有多个CG；（消费者组之间从逻辑上它们是独立的）
					向topic订阅消费消息的单位是 consumers，当然它其中也可以只有一个消费者（consumer）；
					一个分区(partition)里面的数据只会由分组(cgroup)中的一个消费者处理，同分组的其他消费者不会重复处理，也是为了提高吞吐量；
					消费者组中的消费者数量<=分区数量；如果大于分区数量，多出来的消费者会处于收不到消息的状态，造成不必要的浪费；


	subscribe函数订阅主题：分组下有消费者曾经提交过offset，则从提交过的offset处开始消费；
							分组下没消费者提交过offset，则从当前添加消息的最后位置开始消费；

	assign函数指定分区：分组下有消费者曾经提交过offset，则从提交过的offset处开始消费；
						分组下没有消费者提交过offset，则从当前添加消息的最后位置开始消费；

	auto.offset.reset：分组下有消费者曾经提交过offset{earliest/latest}，从提交过的offset处开始消费；
						分组下没有消费者曾经提交过offset{earlist：从分区开头位置开始消费；
															latest：从当前添加消息的最后位置开始消费}；


·kafka group_id解释：
	topic到group是发布订阅的通信方式，即一条topic会被所有的group消费，属于一对多模式；group到consumer是点对点通信方式，属于一对一模式。

	不使用group的话，启动10个consumer消费一个topic，这10个consumer都能得到topic的所有数据，相当于这个topic中的任一条消息被消费10次。

	使用group的话，连接时带上groupid，topic的消息会分发到10个consumer上，每条消息只被消费1次。

	在一个消费者组当中可以有一个或者多个消费者实例，它们共享一个公共的group ID，组ID是一个字符串，用来唯一标志一个消费者组，组内的所有消费者协调在一起来消费订阅主题的所有分区，但是同一个topic下的某个分区只能被消费者组中的一个消费者消费，不同消费者组中的消费者可以消费相同的分区。

	需要注意的是，如果消费者组当中消费者的数量超过了订阅主题分区的数量，那么多余的消费者就会被闲置，不会受到任何消息。

	同一个Topic对应很多的分区，这topic消息，可以被很多组消费者消费，但是同一个topic下的某个分区，只能被一个消费者组当中的一个消费者消费。
	分区0，被消费者1消费，同时还被消费者2消费 --> 这个就是错的。
	一个消费者组的一个消费者，可以消费一个topic下的多个分区。
	同一个topic下的某个分区，可以被多个消费者组、消费者消费。




·更换group.id时 kafka从哪开始消费：
	设置消费者properties的两个参数：
		consumer.group.id
		properties.setProperty("auto.offset.reset", "earliest”) // latest

	注意：只要不更改group.id，每次重新消费kafka，都是从上次消费结束的地方继续开始，不论"auto.offset.reset”属性设置的是什么

	场景一：Kafka上在实时被灌入数据，但kafka上已经积累了两天的数据，如何从最新的offset开始消费？（最新指相对于当前系统时间最新）
		1.将group.id换成新的名字(相当于加入新的消费组)
		2.网上文章写还要设置 properties.setProperty("auto.offset.reset", "latest”)
		实验发现即使不设置这个，只要group.id是全新的，就会从最新的的offset开始消费。

	场景二：kafka在实时在灌入数据，kafka上已经积累了两天的数据，如何从两天前最开始的位置消费？
		1.将group.id换成新的名字
		2.properties.setProperty("auto.offset.reset", "earliest”)
	 
	场景三：不更改group.id，只是添加了properties.setProperty("auto.offset.reset", "earliest”)，consumer会从两天前最开始的位置消费吗？
			不会，只要不更改消费组，只会从上次消费结束的地方继续消费

	场景四：不更改group.id，只是添加了properties.setProperty("auto.offset.reset", "latest”)，consumer会从距离现在最近的位置消费吗？
			不会，只要不更改消费组，只会从上次消费结束的地方继续消费

	应用：正式打包上线前应该使用新的group.id，以便于从kafka最新的位置开始消费。
			只要将group.id换成全新的，不论"auto.offset.reset”是否设置，设置成什么，都会从最新的位置开始消费




·问题：
	··使用消息队列不可能是单机的（必然是分布式or集群）
		kafka天然是分布式的，往一个topic丢数据，实际上就是往多个broker的partition存储数据；不同broker有同一份topic。

	··数据写到消息队列，可能会存在数据丢失问题，数据在消息队列需要持久化(磁盘？数据库？Redis？分布式文件系统？)
		Kafka会将partition以消息日志的方式(落磁盘)存储起来，通过顺序访问IO和缓存(等到一定的量或时间)才真正把数据写到磁盘上，来提高速度。

	··想要保证消息（数据）是有序的，怎么做？
		Kafka会将数据写到partition，单个partition的写入是有顺序的。如果要保证全局有序，那只能写入一个partition中。如果要消费也有序，消费者也只能有一个。

	··为什么在消息队列中重复消费了数据？
		凡是分布式就无法避免网络抖动、机器宕机等问题的发生，很有可能消费者A读取了数据，还没来得及消费，就挂掉了。Zookeeper发现消费者A挂了，让消费者B去消费原本消费者A的分区，等消费者A重连的时候，发现已经重复消费同一条数据了。(各种各样的情况，消费者超时等等都有可能...)
		如果业务上不允许重复消费的问题，最好消费者那端做业务上的校验（如果已经消费过了，就不消费了）




·kafka producer发送数据：
	··ProducerRecord：发送给kafka broker的key/value值对；
					包含字段有topic/partition/headers/key/value/timestamp；

	··消息格式：每个消息是一个ProducerRecord对象，必须指定消息所属的topic和消息值value，此外还可以指定消息所属的partition以及消息的key；

	··acks=0---生产者成功写入消息之前不会等待任何来自服务器的成功响应；吞吐最高；
		acks=1---只要集群的首领节点收到消息，生产者就会收到一个来自服务器的成功响应；
		acks=all---只有所有参与的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应；保证消息不丢失，但延迟最大；

	1.序列化ProducerRecord有多个构造器，这里使用了三个参数的，topic、key、value；

	2.如果ProducerRecord中指定了Partition，则Partitioner不做任何事情；否则，Partitioner根据消息的key得到一个Partition。这时生产者就知道向哪个Topic下的哪个Partition发送这条消息；

	3.消息被添加到相应的batch中，独立的线程将这些batch发送到Broker上；

	4.broker收到消息会返回一个响应。如果消息成功写入Kafka，则返回RecordMetaData对象，该对象包含了Topic信息、Patition信息、消息在Partition中的Offset信息；若失败，返回一个错误；

	··Kafka发送消息主要有三种方式：1.发送并忘记 2.同步发送 3.异步发送+回调函数；

	··properties.send()：在send之前，会先读取metadata。如果metadata读不到，会一直阻塞在那，直到超时，抛出TimeoutException；
	
	··同步发送消息：某些场景下我们并不需要异步发送消息，这个时候我们可以采取同步发送方式，实现也是非常简单的，我们只需要在send方法后面调用get方法即可；

	··异步发送消息：发送消息的时候需要休眠一下，否则发送时间较长的时候会导致进程提前关闭导致无法调用回调时间。主要是因为KafkaTemplate发送消息是采取异步方式发送的；
	Future是Java自带的实现异步编程的接口，支持返回值的异步，而我们使用Thread或者Runnable都是不带返回值的；




·kafka consumer消费数据：
	··ConsumerRecord：包含字段有topic/partition/offset/timestamp/headers/key/value……
	·· 不同组名可以重复消费；

	··kafka offset机制：存储当前消费分区的偏移量，即使挂了或者再均衡问题引发重新分配partation,也能从正确的位置继续消费；
		# latest: 有提交的offset时，从提交的offset开始，无提交的offset时，消费新产生的数据；
		# earlist： 有提交的offset时，从提交的offset开始，无提交的offset时，从头开始消费；
		# none:  有提交的offset时，从提交的offset开始，存在一个未提交的offset的分区时，抛出异常；

	方式：
	1.指定多主题消费；
		consumer.subscribe(Arrays.asList("t4","t5"));

	2.指定分区消费；
		ArrayList<TopicPartition> list = new ArrayList<TopicPartition>();
	    TopicPartition tp = new TopicPartition("t1", 0);
	    TopicPartition tp2 = new TopicPartition("t4", 0);
	    TopicPartition tp3 = new TopicPartition("t4", 1);
	    TopicPartition tp4 = new TopicPartition("t4", 2);
	    list.add(tp);
	    list.add(tp2);
	    list.add(tp3);
	    list.add(tp4);
	    consumer.assign(list);

	3.手动修改偏移量；
		consumer.commitSync();                //提交当前消费偏移量
	    consumer.commitSync(Map<TopicPartition, OffsetAndMetadata>)    //提交指定偏移量
	    consumer.assign(Arrays.asList(tp));

	4.seek，修改偏移量搜索指针，顺序读取数据；
	    consumer.assign(Arrays.asList(tp));
	    consumer.seek(tp,0);

    ··自动提交：自动提交是在kafka拉取到数据之后就直接提交，这样很容易丢失数据，尤其是在需要事物控制的时候；
    ··手动提交：




·消息模型分两种：队列和发布-订阅式；
				如果所有的消费者都在一个组中，那么这个就变成了队列模型；如果消费者在不同的组中，这就成了发布-订阅模型；






·KafkaTemplate：