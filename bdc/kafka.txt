
·kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者在网站中的所有动作流数据。

·kafka通过zookeeper管理集群，在每台服务器上先安装zookeeper；
	具体管理：
	··探测broker和consumer的添加或移除；
	··负责维护所有partition的领导者/从属者关系（主分区和备份分区），如果主分区挂了，需要选举出备份分区作为主分区；
	··维护topic、partition等元配置信息；
	···。。。
	kafka之间是无法互相发现对方的，每个kafka向zk注册，说我是A节点（broker.id），我是B节点，这样组成了一个kafka集群。每个人通过zk来发现彼此。


·消息模型分两种：队列和发布-订阅式；
				如果所有的消费者都在一个组中，那么这个就变成了队列模型；如果消费者在不同的组中，这就成了发布-订阅模型；


·KafkaTemplate：kafka的模板类提供可调用的API。



·相关概念： 
	broker：一台kafka服务器就是一个broker。一个Kafka集群由多个broker组成；
			一个broker可以容纳多个topic，一个topic会分为多个partition。实际上partition会分布在不同的broker中，即同一份topic会分布在多个不同的broker上。由此得知：Kafka是天然分布式的；
			消费者可以订阅一个或多个主题（topic），并从broker拉数据，从而消费这些已发布的消息；

	topic：一个队列或者主题；
			为了提高一个队列(topic)的吞吐量，kafka会把topic进行分区(Partition)；
			Topic是Kafka数据写入操作的基本单元，可以指定副本；
			一个Topic包含一个或多个Partition，建议创建Topic的时候可以手动指定Partition个数，个数与broker个数相当；
			每条消息属于且仅属于一个Topic；
			Producer发布数据时，必须指定将该消息发布到哪个Topic；
			Consumer订阅消息时，也必须指定订阅哪个Topic的信息；
			往一个topic丢数据，实际上就是往多个broker的partition存储数据；

	partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。
				partition中的每条消息都会被分配一个有序的id（offset）。kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体（多个partition间）的顺序。 
				生产者往topic里丢数据是存在partition上的，而partition持久化到磁盘是IO顺序访问的，并且是先写缓存，隔一段时间或者数据量足够大的时候才批量写入磁盘的。 

				在kafka集群中，每个Partition都有多个副本，其中一个副本叫做leader，其他的副本叫做follower。
				假设一个Topic拆分为了3个Partition，分别是Partition0，Partiton1，Partition2，此时每个Partition都有2个副本。
				比如Partition0有一个副本是Leader，另外一个副本是Follower，Leader和Follower两个副本是分布在不同机器上的。
				这样的多副本冗余机制，可以保证任何一台机器挂掉，都不会导致数据彻底丢失，因为起码还是有副本在别的机器上的。

	offset：	Kafka就是用offset来表示消费者的消费进度到哪了，每个消费者会都有自己的offset。说白了offset就是表示消费者的消费进度。
			在以前版本的Kafka，这个offset是由Zookeeper来管理的，后来Kafka开发者认为Zookeeper不合适大量的删改操作，于是把offset在broker以内部topic(__consumer_offsets)的方式来保存起来。

			kafka的topic中的每个消费组消费的下标；

			kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。
			当然the first offset就是00000000000.kafka。

	producer：消息生产者，向broker发消息的客户端；

	consumer：消息消费者，向broker取消息的客户端；

	message：消息是kafka处理的对象。在kafka中，消息是被发布到broker的topic中。而consumer也是从相应的topic中拿数据。也就是说，message是按topic存储的；
			 每个消息(也叫记录record)是由一个key，一个value和时间戳构成；

	consumer group：将topic消息的广播发给consumer的手段；一个topic可以有多个CG；（消费者组之间从逻辑上它们是独立的）
					向topic订阅消费消息的单位是 consumers，当然它其中也可以只有一个消费者（consumer）；
					一个分区(partition)里面的数据只会由分组(cgroup)中的一个消费者处理，同分组的其他消费者不会重复处理，也是为了提高吞吐量；
					消费者组中的消费者数量<=分区数量；如果大于分区数量，多出来的消费者会处于收不到消息的状态，造成不必要的浪费；

	分区再均衡：分区的所有权从一个消费者转到另一个消费者被称为再均衡。一般新增消费者，消费者关闭或改变分区数都会发生再均衡。



·kafka group_id解释：
	topic到group是发布订阅的通信方式，即一条topic会被所有的group消费，属于一对多模式；group到consumer是点对点通信方式，属于一对一模式。

	不使用group的话，启动10个consumer消费一个topic，这10个consumer都能得到topic的所有数据，相当于这个topic中的任一条消息被消费10次。

	使用group的话，连接时带上groupid，topic的消息会分发到10个consumer上，每条消息只被消费1次。

	在一个消费者组当中可以有一个或者多个消费者实例，它们共享一个公共的group ID，组ID是一个字符串，用来唯一标志一个消费者组，组内的所有消费者协调在一起来消费订阅主题的所有分区，但是同一个topic下的某个分区只能被消费者组中的一个消费者消费，不同消费者组中的消费者可以消费相同的分区。

	需要注意的是，如果消费者组当中消费者的数量超过了订阅主题分区的数量，那么多余的消费者就会被闲置，不会受到任何消息。

	一个消费者组的一个消费者，可以消费一个topic下的多个分区。
	同一个topic下的某个分区，可以被多个消费者组、消费者消费。




·更换group.id时 kafka从哪开始消费：
	设置消费者properties的两个参数：
		consumer.group.id
		properties.setProperty("auto.offset.reset", "earliest”) // latest

	注意：只要不更改group.id，每次重新消费kafka，都是从上次消费结束的地方继续开始，不论"auto.offset.reset”属性设置的是什么

	场景一：Kafka上在实时被灌入数据，但kafka上已经积累了两天的数据，如何从最新的offset开始消费？（最新指相对于当前系统时间最新）
		1.将group.id换成新的名字(相当于加入新的消费组)
		2.网上文章写还要设置 properties.setProperty("auto.offset.reset", "latest”)
		实验发现即使不设置这个，只要group.id是全新的，就会从最新的的offset开始消费。

	场景二：kafka在实时灌入数据，kafka上已经积累了两天的数据，如何从两天前最开始的位置消费？
		1.将group.id换成新的名字
		2.properties.setProperty("auto.offset.reset", "earliest”)
	 
	场景三：不更改group.id，只是添加了properties.setProperty("auto.offset.reset", "earliest”)，consumer会从两天前最开始的位置消费吗？
			不会，只要不更改消费组，只会从上次消费结束的地方继续消费

	场景四：不更改group.id，只是添加了properties.setProperty("auto.offset.reset", "latest”)，consumer会从距离现在最近的位置消费吗？
			不会，只要不更改消费组，只会从上次消费结束的地方继续消费

	应用：正式打包上线前应该使用新的group.id，以便于从kafka最新的位置开始消费。
			只要将group.id换成全新的，不论"auto.offset.reset”是否设置，设置成什么，都会从最新的位置开始消费




·问题：
	··使用消息队列不可能是单机的（必然是分布式or集群）
		kafka天然是分布式的，往一个topic丢数据，实际上就是往多个broker的partition存储数据；不同broker有同一份topic。

	··数据写到消息队列，可能会存在数据丢失问题，数据在消息队列需要持久化(磁盘？数据库？Redis？分布式文件系统？)
		Kafka会将partition以消息日志的方式(落磁盘)存储起来，通过顺序访问IO和缓存(等到一定的量或时间)才真正把数据写到磁盘上，来提高速度。

	··想要保证消息（数据）是有序的，怎么做？
		Kafka会将数据写到partition，单个partition的写入是有顺序的。如果要保证全局有序，那只能写入一个partition中。如果要消费也有序，消费者也只能有一个。

	··为什么在消息队列中重复消费了数据？
		凡是分布式就无法避免网络抖动、机器宕机等问题的发生，很有可能消费者A读取了数据，还没来得及消费，就挂掉了。Zookeeper发现消费者A挂了，让消费者B去消费原本消费者A的分区，等消费者A重连的时候，发现已经重复消费同一条数据了。(各种各样的情况，消费者超时等等都有可能...)
		如果业务上不允许重复消费的问题，最好消费者那端做业务上的校验（如果已经消费过了，就不消费了）

	··acks=all 就可以代表数据一定不会丢失了吗？
		当然不是，如果你的Partition只有一个副本，也就是一个Leader，任何Follower都没有，你认为acks=all有用吗？
		当然没用了，因为ISR【保持同步的副本，含义就是跟Leader始终保持同步的Follower有哪些】里就一个Leader，他接收完消息后宕机，也会导致数据丢失。
		所以说，这个acks=all，必须跟ISR列表里至少有2个以上的副本配合使用，起码是有一个Leader和一个Follower才可以。
		这样才能保证说写一条数据过去，一定是2个以上的副本都收到了才算是成功，此时任何一个副本宕机，不会导致数据丢失。



·kafka丢失消息的情况：消息丢失会发生在Broker，Producer和Consumer三种。
	··Broker丢失消息是由于Kafka本身的原因造成的，kafka为了得到更高的性能和吞吐量，将数据异步批量的存储在磁盘中。消息的刷盘过程，为了提高性能，减少刷盘次数，kafka采用了批量刷盘的做法。即，按照一定的消息量，和时间间隔进行刷盘。这种机制也是由于linux操作系统决定的。将数据存储到linux操作系统种，会先存储到页缓存（Page cache）中，按照时间或者其他条件进行刷盘（从page cache到file），或者通过fsync命令强制刷盘。数据在page cache中时，如果系统挂掉，数据会丢失。





·kafka producer发送数据：
	··ProducerRecord：发送给kafka broker的key/value值对；
					包含字段有topic/partition/headers/key/value/timestamp；

	··消息格式：每个消息是一个ProducerRecord对象，必须指定消息所属的topic和消息值value，此外还可以指定消息所属的partition以及消息的key；

	··关于acks=？
		0：意味着producer不等待broker同步完成的确认，继续发送下一条(批)信息。此选项吞吐最高，提供了最低的延迟，但是最弱的持久性。当服务器发生故障时，就很可能发生数据丢失。例如leader已经死亡，producer不知情，还会继续发送消息，broker接收不到数据就会导致数据丢失。
		
		1：意味着producer要等待leader成功收到数据并得到确认，才发送下一条message。此选项提供了较好的持久性、较低的延迟性。如果Partition的Leader死亡，follwer尚未复制，数据就会丢失。这种设置其实是kafka默认的设置。
		
		-1(all)：意味着producer需等待leader将消息同步给follower，得到follwer确认，才发送下一条数据。此选项保证消息不丢失，但延迟最大；


	··Kafka发送消息主要有三种方式：1.发送并忘记 2.同步发送 3.异步发送+回调函数；
		1.producer.send(record)：在send之前，会先读取metadata。如果metadata读不到，会一直阻塞在那，直到超时，抛出TimeoutException；
		
		2.同步发送消息：某些场景下我们并不需要异步发送消息，这个时候我们可以采取同步发送方式，实现也是非常简单的，我们只需要在send()方法后面调用get()方法即可；

		3.异步发送消息：发送消息的时候需要休眠一下，否则发送时间较长的时候会导致进程提前关闭导致无法调用回调时间。主要是因为KafkaTemplate发送消息是采取异步方式发送的；
		Future是Java自带的实现异步编程的接口，支持返回值的异步，而我们使用Thread或者Runnable都是不带返回值的；

			3.1.序列化ProducerRecord有多个构造器，这里使用了三个参数的，topic、key、value；
			3.2.如果ProducerRecord中指定了Partition，则Partitioner不做任何事情；否则，Partitioner根据消息的key得到一个Partition。这时生产者就知道向哪个Topic下的哪个Partition发送这条消息；
			3.3.消息被添加到相应的batch中，独立的线程将这些batch发送到Broker上；
			3.4.broker收到消息会返回一个响应。如果消息成功写入Kafka，则返回RecordMetaData对象，该对象包含了Topic信息、Patition信息、消息在Partition中的Offset信息；若失败，返回一个错误；




·kafka consumer消费数据：
	··ConsumerRecord：包含字段有topic/partition/offset/timestamp/headers/key/value……

	··kafka offset机制：存储当前消费分区的偏移量，即使挂了或者再均衡问题引发重新分配partation,也能从正确的位置继续消费；
		# latest: 有提交的offset时，从提交的offset开始，无提交的offset时，消费新产生的数据；
		# earlist： 有提交的offset时，从提交的offset开始，无提交的offset时，从头开始消费；
		# none:  有提交的offset时，从提交的offset开始，存在一个未提交的offset的分区时，抛出异常；

	··方式：
		subscribe函数订阅主题：分组下有消费者曾经提交过offset，则从提交过的offset处开始消费；
								分组下没消费者提交过offset，则从当前添加消息的最后位置开始消费；

		assign函数指定分区：分组下有消费者曾经提交过offset，则从提交过的offset处开始消费；
							分组下没有消费者提交过offset，则从当前添加消息的最后位置开始消费；

		auto.offset.reset：分组下有消费者曾经提交过offset{earliest/latest}，从提交过的offset处开始消费；
							分组下没有消费者曾经提交过offset{earlist：从分区开头位置开始消费；latest：消费新产生的该分区下的数据，这就会导致无法读取旧数据}；

		1.指定多主题消费；
			consumer.subscribe(Arrays.asList("t4","t5"));

		2.指定分区消费；
			ArrayList<TopicPartition> list = new ArrayList<TopicPartition>();
		    TopicPartition tp1 = new TopicPartition("t1", 0);	//(topic, partition)
		    TopicPartition tp2 = new TopicPartition("t4", 0);
		    TopicPartition tp3 = new TopicPartition("t4", 1);
		    TopicPartition tp4 = new TopicPartition("t4", 2);
		    list.add(tp1);
		    list.add(tp2);
		    list.add(tp3);
		    list.add(tp4);
		    consumer.assign(list);

		3.手动修改偏移量；
			consumer.commitSync();                //提交当前消费偏移量
		    consumer.commitSync(Map<TopicPartition, OffsetAndMetadata>)    //提交指定偏移量
		    consumer.assign(Arrays.asList(tp));

		4.seek()：修改偏移量搜索指针，顺序读取数据；
		    consumer.assign(Arrays.asList(tp));
		    consumer.seek(tp,0);

    ··提交偏移量：5种；
	    ···自动提交：自动提交是在kafka拉取到数据之后就直接提交。
   			有两个很重要的参数：
			enable.auto.commit=true（是否开启自动提交，true or false）
			auto.commit.interval.ms=5000（提交偏移量的时间间隔，默认5000ms）

			每隔5秒，消费者会自动把从poll方法接收到的最大偏移量提交上去。自动提交是在轮询中进行，消费者每次轮询时都会检查是否提交该偏移量。可是这种情况在发生再均衡时会发生重复消费和丢失消息的情况。如果是同步处理数据，再均衡时很容易发生消息重复，如果是异步处理数据，则易发生数据丢失。可以通过修改提交时间间隔来更频繁地提交偏移量，减小可能出现重复消息的时间窗，不过这种情况也是无法完全避免问题。

				重复消费：如果提交的偏移量小于客户端处理 的最后一个消息的偏移量 ，那么处于两个偏移量之间的 消息就会被重复处理。如果我们设auto.commit.interval.ms=60000，16:34首次提交偏移量62，此时又拉取了2条消息，此时分区2对应的消费者宕机，发生了分区再均衡，分区2的消息由另一个消费者消费，新的消费者会读取16:34提交的那个偏移量，这样就会发生重复消费了。

				丢失消息：如果提交的偏移量大于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的 消息将会丢失。消费者一次poll100条新消息，并且提交了偏移量，此时消费者还没处理完，就宕机了，又发生了再均衡，由另一个消费者消费该分区的消息，新的消费者会读取旧消费者最后一次提交的偏移量，此时就会发生消息丢失了。

	    ···手动提交当前偏移量：
	    	大部分开发者通过控制偏移量提交时间来消除丢失消息的可能性，并在发生再均衡时减少重复消息的数量。消费者API提供了另一种提交偏移量的方式，开发者可以在必要的时候 提交当前偏移盘，而不是基于时间间隔。
	    	取消自动提交，设置enable.auto.commit=false，让应用程序决定何时提交偏移量。使用commitSync()提交偏移量最简单也最可靠。这个API会提交由poll()方法返回的最新偏移量，提交成功后马上返回，如果提交失败就抛出异常。consumer.commitSync();

		···异步提交：手动提交不足之处在于提交请求后，broker对提交请求响应之前应用程序会一直阻塞。这样就会限制应用程序的吞吐量。虽然可以通过降低提交频率来提升吞吐量，但一旦发生再均衡，会增加重复消息的数量。另一种选择是异步提交API。我们只管发送提交请求，无需等待 broker的响应。consumer.commitAsync();

			在成功提交或碰到无怯恢复的错误之前，commitSync()会一直重试(应用程序也一直阻塞)，但是 commitAsync()不会，这也是 commitAsync()不好的一个地方。因为 commitAsync()也支持回调，在 broker作出响应时会执行回调。回调经常被用于记录提交错误或生成度量指标，不过如果你要用它来进行重试，一定要注意提交的顺序。


		···同步异步组合提交：如果提交失败发生在关闭消费者或者再均衡前的最后一次提交，那么就要确保提交能够成功。这个时候就需要使用同步异步组合提交。

		···提交特定偏移量：如果想要在批次中间提交偏移量，消费者API允许在调用commitSync和commitAsync时传递希望提交的分区和偏移量。







